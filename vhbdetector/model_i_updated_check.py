# -*- coding: utf-8 -*-
"""model_i_updated.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cyeJoRjlxIkSqdAZOGnfQYqr-7kgFbjq
"""

# Commented out IPython magic to ensure Python compatibility.
import pickle
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
# %matplotlib inline
from sklearn.model_selection import train_test_split
from tensorflow.keras.layers import *
from tensorflow.keras.models import Sequential
from tensorflow.keras.utils import to_categorical
from tensorflow.keras import callbacks
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.regularizers import L1, L2, L1L2
from tensorflow.keras.utils import plot_model

from google.colab import drive
drive.mount('/content/drive')

file = open("/content/drive/MyDrive/Software Project/X_normalized.pickle", "rb")
X = pickle.load(file)
file = open("/content/drive/MyDrive/Software Project/Y.pickle", "rb")
Y = pickle.load(file)

X = X.reshape(1009, 179, 60, 60, 1)
X.shape

Y.shape

import pandas as pd
pd.Series(Y).value_counts()

# Using Keras's to_categorical method to convert labels into one-hot-encoded vectors
Y = to_categorical(Y)

Y.shape

Y

from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.5, stratify = Y, shuffle = True, random_state = 5)

X_train.shape, Y_train.shape, X_test.shape, Y_test.shape

np.unique(Y)

Y.shape[1]

len(list(range(Y.shape[1])))

del X
del Y

CLASSES_LIST = list(range(Y_train.shape[1]))
num_classes = len(CLASSES_LIST)
SEQUENCE_LENGTH = 179
BATCH_SIZE = 16
IMAGE_HEIGHT = IMAGE_WIDTH = 60
EPOCHS = 400
learning_rate = 0.0001

def create_convlstm_model():
    '''
    This function will construct the required convlstm model.
    Returns:
        model: It is the required constructed convlstm model.
    '''

    # We will use a Sequential model for model construction
    model = Sequential()

    # Define the Model Architecture.
    ########################################################################################################################
    
    model.add(ConvLSTM2D(filters = 8, kernel_size = (3, 3), activation = 'tanh',data_format = "channels_last",
                         recurrent_dropout=0.1, return_sequences=True, input_shape = (SEQUENCE_LENGTH, IMAGE_HEIGHT, IMAGE_WIDTH, 1)))
    
    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))
    model.add(TimeDistributed(Dropout(0.3)))
    
    model.add(ConvLSTM2D(filters = 16, kernel_size = (3, 3), activation = 'tanh', data_format = "channels_last",
                         recurrent_dropout=0.1, return_sequences=True))
    
    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))
    model.add(TimeDistributed(Dropout(0.3)))
    
    model.add(ConvLSTM2D(filters = 16, kernel_size = (3, 3), activation = 'tanh', data_format = "channels_last",
                         recurrent_dropout=0.1, return_sequences=True))
    
    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))
    model.add(TimeDistributed(Dropout(0.3)))

    model.add(ConvLSTM2D(filters = 32, kernel_size = (3, 3), activation = 'tanh', data_format = "channels_last",
                         recurrent_dropout=0.1, return_sequences=True))
    
    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))
    model.add(TimeDistributed(Dropout(0.3)))
    
    model.add(Flatten())

    ##model.add(Dense(65536, activation = "relu"))

    model.add(Dense(1024, activation = "relu"))

    model.add(Dense(512, activation = "relu"))
    
    model.add(Dense(num_classes, activation = "softmax"))
    
    ########################################################################################################################
     
    # Display the models summary.
    model.summary()
    return model

def build_convnet(shape=(60, 60, 1)):
    momentum = .9
    model = Sequential()
    model.add(Conv2D(16, (3,3), input_shape=shape, padding='same', activation='relu', kernel_regularizer=L1L2(l1=1e-5, l2=1e-4), bias_regularizer=L2(1e-4),
    activity_regularizer=L2(1e-5))) #64
    #model.add(Conv2D(16, (3,3), padding='same', activation='relu')) #64
    model.add(BatchNormalization(momentum=momentum))
    
    model.add(MaxPool2D())
    
    model.add(Conv2D(, (3,3), padding='same', activation='relu', kernel_regularizer=L1L2(l1=1e-5, l2=1e-4), bias_regularizer=L2(1e-4),
    activity_regularizer=L2(1e-5))) #128
    #model.add(Conv2D(32, (3,3), padding='same', activation='relu')) #128
    model.add(BatchNormalization(momentum=momentum))
    
    model.add(MaxPool2D())
    
    #model.add(Conv2D(256, (3,3), padding='same', activation='relu'))
    #model.add(Conv2D(256, (3,3), padding='same', activation='relu'))
    #model.add(BatchNormalization(momentum=momentum))
    
    #model.add(MaxPool2D())
    
    #model.add(Conv2D(512, (3,3), padding='same', activation='relu'))
    #model.add(Conv2D(512, (3,3), padding='same', activation='relu'))
    #model.add(BatchNormalization(momentum=momentum))
    
    # flatten...
    model.add(GlobalMaxPool2D())
    return model



def action_model(shape = (SEQUENCE_LENGTH, IMAGE_HEIGHT, IMAGE_WIDTH, 1), num_classes = 5):
    # Create our convnet with (112, 112, 3) input shape
    convnet = build_convnet(shape[1:])
    
    # then create our final model
    model = Sequential()
    # add the convnet with (5, 112, 112, 3) shape
    model.add(TimeDistributed(convnet, input_shape=shape))
    # here, you can also use GRU or LSTM
    #model.add(GRU(64))
    model.add(Flatten())

    # and finally, we make a decision network
    model.add(Dense(1024, activation='relu', kernel_regularizer=L1L2(l1=1e-5, l2=1e-4), bias_regularizer=L2(1e-4),
    activity_regularizer=L2(1e-5)))

    #model.add(Dropout(.5))
    model.add(Dense(64, activation='relu'))
    #model.add(Dropout(.5))
    #model.add(Dense(128, activation='relu'))
    #model.add(Dropout(.5))
    #model.add(Dense(64, activation='relu'))
    model.add(Dense(num_classes, activation='softmax'))
    return model

# Construct the required convlstm model.
#convlstm_model = create_convlstm_model()
convlstm_model = action_model(shape = (179, 60, 60, 1))

# Display the success message. 
print("Model Created Successfully!")

convlstm_model.summary()

# Plot the structure of the contructed model.
plot_model(convlstm_model, to_file = 'convlstm_model_structure_plot.png', show_shapes = True, show_layer_names = True)

from tensorflow.keras.optimizers import Adam

callbacks_params = [
             callbacks.EarlyStopping(monitor='val_loss', mode = "min", patience=150),
             callbacks.ReduceLROnPlateau(verbose=1)]
             #callbacks.ModelCheckpoint('../input/honeybees/weights.{epoch:02d}-{val_loss:.2f}.hdf5', verbose=1)]

# Create an Instance of Early Stopping Callback
early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 200, mode = 'min', restore_best_weights = True)

# Compile the model and specify loss function, optimizer and metrics values to the model
convlstm_model.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = learning_rate), metrics = ["accuracy"])

# Start training the model.
history = convlstm_model.fit(x = X_train, y = Y_train, epochs = EPOCHS, batch_size = BATCH_SIZE,
                             shuffle = True, validation_data = (X_test, Y_test),
                             callbacks = [early_stopping_callback])

print("Tensorflow version " + tf.__version__)

try:
  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection
  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])
except ValueError:
  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')

tf.config.experimental_connect_to_cluster(tpu)
tf.tpu.experimental.initialize_tpu_system(tpu)
tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)

# Create an Instance of Early Stopping Callback
early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 100, mode = 'min', restore_best_weights = True)

with tpu_strategy.scope():
  model = create_convlstm_model()
  model.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = learning_rate), metrics = ["accuracy"])
model.fit(x = X_train, y = Y_train, epochs = EPOCHS, batch_size = BATCH_SIZE,
                             shuffle = True, validation_data = (X_test, Y_test),
                             callbacks = [early_stopping_callback])

